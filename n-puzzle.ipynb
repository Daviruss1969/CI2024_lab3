{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifications of the problem : [https://en.wikipedia.org/wiki/15_puzzle](https://en.wikipedia.org/wiki/15_puzzle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's all the librairies needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the puzzle dimensions, and create a structure to store the possibles actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 2\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "    src: int\n",
    "    dst: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then have to define two important functions:\n",
    "- One that return all the possible actions for a given state.\n",
    "- One that perform an action\n",
    "\n",
    "Since those functions will be called many times, we have to optimize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list[Action]:\n",
    "    \"\"\"Returns all the possible actions for a given state\"\"\"\n",
    "    x, y = np.argwhere(state == 0)[0] # Get the indexes of the 0 in the puzzle\n",
    "\n",
    "    # Add all possible actions by checking boundaries\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(Action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(Action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(Action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(Action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "\n",
    "def do_action(state: np.ndarray, action: Action) -> np.ndarray:\n",
    "    \"\"\"Returns a new state that perform the given action on a given state\"\"\"\n",
    "    new_state = state.copy()\n",
    "    new_state[action.src], new_state[action.dst] = new_state[action.dst], new_state[action.src]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the problem, starting from the solution we randomize it many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "SOLUTION = np.ndarray([])\n",
    "\n",
    "def init_problem() -> np.ndarray[np.ndarray[int]]:\n",
    "    \"\"\"Return a N-puzzle problem and its solution where N is given by PUZZLE_DIM\"\"\"\n",
    "    solution = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM)) # Create matrix\n",
    "\n",
    "    # Randomize it\n",
    "    state = solution.copy()\n",
    "    for r in range(RANDOMIZE_STEPS):\n",
    "        state = do_action(state, choice(available_actions(state)))\n",
    "\n",
    "    return state, solution\n",
    "\n",
    "state, SOLUTION = init_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First naive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first approach, I just wanted something that works, no matter the efficiency of the algorithm.\n",
    "\n",
    "I implemented a simple naive Depth First Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_puzzle_naive(state: np.ndarray[np.ndarray[int]]) -> np.ndarray[np.ndarray[int]] :\n",
    "    \"\"\"Return the solution of an N puzzle for a given initial state\"\"\"\n",
    "    frontier = list()\n",
    "    while state is not None and not np.array_equal(SOLUTION, state):\n",
    "        # Append nodes made by possibles actions in the frontier for the current state\n",
    "        for action in available_actions(state):\n",
    "            new_state = do_action(state, action)\n",
    "            frontier.append(new_state)\n",
    "        \n",
    "        # Get the last state from the frontier (DFS)\n",
    "        state = frontier.pop()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't run it, since it can be very very long. But we have a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state = n_puzzle_naive(state.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is apparent: adding the same state to the frontier repeatedly makes the algorithm perform the same searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth First Search with explored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to solve it is to add a set that keeps track of the explored state, avoiding re-searching from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, let's implement a structure that simply stores the current state and steps in order to compute the efficiency. In the algorithm, we will also have a counter of all the visited nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Node:\n",
    "    state: np.ndarray[np.ndarray[int]]\n",
    "    step: int = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the explored states, we will use a set and map the NumPy matrix into a hashable tuple in order to see if it is already in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_puzzle_dfs(state: np.ndarray[np.ndarray[int]]) -> tuple[np.ndarray[np.ndarray[int]], int, int] :\n",
    "    \"\"\"Return the solution of an N puzzle for a given initial state\"\"\"\n",
    "    frontier: list[Node] = [Node(state=state)] # heap of nodes to explore\n",
    "    explored = set()    # Set of explored states\n",
    "    cost = 0\n",
    "\n",
    "    while frontier:\n",
    "        cost += 1\n",
    "\n",
    "        # Get the last state from the frontier (DFS)\n",
    "        current_node = frontier.pop()\n",
    "\n",
    "        # Goal function\n",
    "        if np.array_equal(SOLUTION, current_node.state):\n",
    "            return current_node.state, current_node.step, cost\n",
    "\n",
    "        # Explore all possible actions\n",
    "        for action in available_actions(current_node.state):\n",
    "            new_state = do_action(current_node.state, action)\n",
    "\n",
    "            # Check for state already explored\n",
    "            new_tuple = tuple(map(tuple, new_state))\n",
    "            if new_tuple in explored:\n",
    "                continue\n",
    "            explored.add(new_tuple)\n",
    "\n",
    "            frontier.append(Node(new_state, current_node.step + 1))\n",
    "\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the algorithm and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the solution : 10 , cost of the solution :  12\n"
     ]
    }
   ],
   "source": [
    "# Perform algorithm\n",
    "final_state, quality, cost = n_puzzle_dfs(state.copy())\n",
    "\n",
    "# Show results\n",
    "if final_state is None:\n",
    "    print(\"No solutions founded\")\n",
    "else:\n",
    "    print(\"Quality of the solution :\", quality, \", cost of the solution : \", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this is way better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to increase the problem size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the solution : 12430 , cost of the solution :  12776\n"
     ]
    }
   ],
   "source": [
    "PUZZLE_DIM = 3\n",
    "state, SOLUTION = init_problem()\n",
    "\n",
    "# Perform algorithm\n",
    "final_state, quality, cost = n_puzzle_dfs(state.copy())\n",
    "\n",
    "# Show results\n",
    "if final_state is None:\n",
    "    print(\"No solutions founded\")\n",
    "else:\n",
    "    print(\"Quality of the solution :\", quality, \", cost of the solution : \", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still very efficient for 3-puzzle, but not for 4-puzzle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breadth First Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply tweak a bit the algorithm to implement Bread First Search (BFS). We should increase the quality of the solution (decrease the value), but also the cost. Indeed, this is a tradeoff between quality and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_puzzle_bfs(state: np.ndarray[np.ndarray[int]]) -> tuple[np.ndarray[np.ndarray[int]], int, int] :\n",
    "    \"\"\"Return the solution of an N puzzle for a given initial state\"\"\"\n",
    "    frontier: list[Node] = [Node(state=state)] # heap of nodes to explore\n",
    "    explored = set()    # Set of explored states\n",
    "    cost = 0\n",
    "\n",
    "    while frontier:\n",
    "        cost += 1\n",
    "\n",
    "        # Get the first state from the frontier (BFS)\n",
    "        current_node = frontier.pop(0)\n",
    "\n",
    "        # Goal function\n",
    "        if np.array_equal(SOLUTION, current_node.state):\n",
    "            return current_node.state, current_node.step, cost\n",
    "\n",
    "        # Explore all possible actions\n",
    "        for action in available_actions(current_node.state):\n",
    "            new_state = do_action(current_node.state, action)\n",
    "\n",
    "            # Check for state already explored\n",
    "            new_tuple = tuple(map(tuple, new_state))\n",
    "            if new_tuple in explored:\n",
    "                continue\n",
    "            explored.add(new_tuple)\n",
    "\n",
    "            frontier.append(Node(new_state, current_node.step + 1))\n",
    "\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the algorithm and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the solution : 24 , cost of the solution :  139344\n"
     ]
    }
   ],
   "source": [
    "# Perform algorithm\n",
    "final_state, quality, cost = n_puzzle_bfs(state.copy())\n",
    "\n",
    "# Show results\n",
    "if final_state is None:\n",
    "    print(\"No solutions founded\")\n",
    "else:\n",
    "    print(\"Quality of the solution :\", quality, \", cost of the solution : \", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the value of the quality is minimized while the cost goes up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of the solutions is that they are informed strategies, so every state has the same weight.\n",
    "\n",
    "In reality, we know that in the case of the n-puzzle, we can say that one state is closer than another one of the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Best First"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution can be to have a sort of ordering inside our frontier.\n",
    "\n",
    "So first, we need a function that estimate the quality of a state of the solution. Let's use manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's precompute the target positions of the solutions in order to optimize a bit the computation of manhattan distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_target_positions() -> dict[int, tuple[int, int]]:\n",
    "    \"\"\"Return a dictionary that contains the target indexes of one entry of the n-puzzle\"\"\"\n",
    "    target_positions = {}\n",
    "    for x in range(PUZZLE_DIM):\n",
    "        for y in range(PUZZLE_DIM):\n",
    "            target_positions[SOLUTION[x, y]] = (x, y)\n",
    "    return target_positions\n",
    "\n",
    "TARGET_POSITIONS = precompute_target_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(state: np.ndarray) -> int:\n",
    "    \"\"\"Compute the manhattan distance bewteen a state and the solution\"\"\"\n",
    "    total_distance = 0\n",
    "\n",
    "    # Sum each difference of distances\n",
    "    for x in range(PUZZLE_DIM):\n",
    "        for y in range(PUZZLE_DIM):\n",
    "            value = state[x, y]\n",
    "            if value == 0:\n",
    "                continue  # Skip tile 0\n",
    "            target_x, target_y = TARGET_POSITIONS[value]\n",
    "            total_distance += abs(target_x - x) + abs(target_y - y)\n",
    "\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to update our Node structure in order to include a priority field that will contain the manhattan distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(order=True)\n",
    "class Node:\n",
    "    priority: int\n",
    "    state: list[list[int]] = field(compare=False)\n",
    "    step: int = field(compare=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's implement our algorithm, it will be pretty similar to the previous one but the frontier will be a priority queue implemented with the heapq module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop, heappush\n",
    "\n",
    "def n_puzzle_gbf(state):\n",
    "    \"\"\"Return the solution of an N puzzle for a given initial state\"\"\"\n",
    "    frontier: list[Node] = [] # Use a heap for storing the states\n",
    "    heappush(frontier, Node(manhattan_distance(state), state, 0))\n",
    "    explored = set()\n",
    "    cost = 0\n",
    "\n",
    "    while frontier:\n",
    "        cost += 1\n",
    "        current_node = heappop(frontier) # Get the node with the maximum expected value\n",
    "\n",
    "        # Goal test\n",
    "        if np.array_equal(SOLUTION, current_node.state):\n",
    "            return current_node.state, current_node.step, cost\n",
    "\n",
    "        # Explore all possible actions\n",
    "        for action in available_actions(current_node.state):\n",
    "            new_state = do_action(current_node.state, action)\n",
    "\n",
    "            # Check for state already explored\n",
    "            new_tuple = tuple(map(tuple, new_state))\n",
    "            if new_tuple in explored:\n",
    "                continue\n",
    "            explored.add(new_tuple)\n",
    "\n",
    "            heappush(frontier, Node(manhattan_distance(new_state), new_state, current_node.step + 1))\n",
    "\n",
    "    return None, None, cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the solution : 74 , cost of the solution :  195\n"
     ]
    }
   ],
   "source": [
    "# Perform algorithm\n",
    "final_state, quality, cost = n_puzzle_gbf(state.copy())\n",
    "\n",
    "# Show results\n",
    "if final_state is None:\n",
    "    print(\"No solutions founded\")\n",
    "else:\n",
    "    print(\"Quality of the solution :\", quality, \", cost of the solution : \", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality is worse than the BFS one, but the cost is way lower than the BFS and DFS algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to increase the problem size and see what's happening. At the size of seven, the algorithm can be very long, it depends on the initial shuffling. From eight, the algorithm is too long to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle dimensions : 4 \n",
      "\tquality of the solution : 288 \n",
      "\tcost of the solution : 3263\n",
      "Puzzle dimensions : 5 \n",
      "\tquality of the solution : 440 \n",
      "\tcost of the solution : 2074\n",
      "Puzzle dimensions : 6 \n",
      "\tquality of the solution : 2728 \n",
      "\tcost of the solution : 126306\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 7):\n",
    "    PUZZLE_DIM = i\n",
    "    state, SOLUTION = init_problem()\n",
    "    TARGET_POSITIONS = precompute_target_positions()\n",
    "\n",
    "    # Perform algorithm\n",
    "    final_state, quality, cost = n_puzzle_gbf(state.copy())\n",
    "\n",
    "    # Show results\n",
    "    if final_state is None:\n",
    "        print(\"No solutions founded\")\n",
    "    else:\n",
    "        print(\"Puzzle dimensions :\", i, \"\\n\\tquality of the solution :\", quality, \"\\n\\tcost of the solution :\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did for DFS and BFS. We can implement A* in order to increase the quality of the solution, but the cost will also increase.\n",
    "\n",
    "The implementation will be straightforward since A* only add the actual cost to compute the priority of a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop, heappush\n",
    "\n",
    "def n_puzzle_a_star(state):\n",
    "    \"\"\"Return the solution of an N puzzle for a given initial state\"\"\"\n",
    "    frontier: list[Node] = [] # Use a heap for storing the states\n",
    "    heappush(frontier, Node(manhattan_distance(state), state, 0))\n",
    "    explored = set()\n",
    "    cost = 0\n",
    "\n",
    "    while frontier:\n",
    "        cost += 1\n",
    "        current_node = heappop(frontier) # Get the node with the maximum expected value\n",
    "\n",
    "        # Goal test\n",
    "        if np.array_equal(SOLUTION, current_node.state):\n",
    "            return current_node.state, current_node.step, cost\n",
    "\n",
    "        # Explore all possible actions\n",
    "        for action in available_actions(current_node.state):\n",
    "            new_state = do_action(current_node.state, action)\n",
    "\n",
    "            # Check for state already explored\n",
    "            new_tuple = tuple(map(tuple, new_state))\n",
    "            if new_tuple in explored:\n",
    "                continue\n",
    "            explored.add(new_tuple)\n",
    "\n",
    "            # Add the new state to the frontier\n",
    "            new_step =  current_node.step + 1\n",
    "            heappush(frontier, Node(manhattan_distance(new_state) + new_step, new_state, new_step)) # Add actual cost to the priority of the node\n",
    "\n",
    "    return None, None, cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it and see what's happening.\n",
    "\n",
    "At the size of four, the algorithm can be very long, it depends on the initial shuffling. From five, the algorithm is too long to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle dimensions : 3 \n",
      "\tquality of the solution : 20 \n",
      "\tcost of the solution : 415\n",
      "Puzzle dimensions : 4 \n",
      "\tquality of the solution : 46 \n",
      "\tcost of the solution : 198681\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 5):\n",
    "    PUZZLE_DIM = i\n",
    "    state, SOLUTION = init_problem()\n",
    "    TARGET_POSITIONS = precompute_target_positions()\n",
    "\n",
    "    # Perform algorithm\n",
    "    final_state, quality, cost = n_puzzle_a_star(state.copy())\n",
    "\n",
    "    # Show results\n",
    "    if final_state is None:\n",
    "        print(\"No solutions founded\")\n",
    "    else:\n",
    "        print(\"Puzzle dimensions :\", i, \"\\n\\tquality of the solution :\", quality, \"\\n\\tcost of the solution :\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the quality of the solution increases a lot (the value goes down), but the cost also goes up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude I would choose either the A* algorithm or GBF to solve this problem. Both are good, it depends on what we want as a result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci2024-lab3-93zH8EBI-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifications of the problem : [https://en.wikipedia.org/wiki/15_puzzle](https://en.wikipedia.org/wiki/15_puzzle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from dataclasses import dataclass, field\n",
    "from tqdm.auto import tqdm\n",
    "from icecream import ic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 4\n",
    "\n",
    "action = namedtuple('Action', ['src', 'dst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.src], new_state[action.dst] = new_state[action.dst], new_state[action.src]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 100000/100000 [00:00<00:00, 122391.75it/s]\n",
      "ic| state: array([[1, 2],\n",
      "                  [3, 0]])\n",
      "ic| SOLUTION: array([[1, 2],\n",
      "                     [3, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 0]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "SOLUTION = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\n",
    "state = SOLUTION.copy()\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "\n",
    "ic(state)\n",
    "ic(SOLUTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_puzzle(state):\n",
    "    frontier = list()\n",
    "    while state is not None and not np.array_equal(SOLUTION, state):\n",
    "        for action in available_actions(state):\n",
    "            new_state = do_action(state, action)\n",
    "            frontier.append(new_state)\n",
    "        state = frontier.pop()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state = n_puzzle(state)\n",
    "# ic(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Node:\n",
    "    state: list[list[int]]\n",
    "    step: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_puzzle_with_explored(state) -> tuple[list[list[int]], int, int] :\n",
    "    \"\"\"\n",
    "    Résolution d'un puzzle en évitant les états redondants.\n",
    "    Utilise une recherche en profondeur (DFS) avec un ensemble pour mémoriser les états visités.\n",
    "    \"\"\"\n",
    "    frontier: list[Node] = [Node(state=state)]  # La pile des états à explorer\n",
    "    explored = set()    # Ensemble des états déjà explorés\n",
    "    cost = 0\n",
    "    while frontier:\n",
    "        cost += 1\n",
    "\n",
    "        # Récupère le prochain état à explorer\n",
    "        current_node = frontier.pop()\n",
    "\n",
    "        # Vérifie si la solution est atteinte\n",
    "        if np.array_equal(SOLUTION, current_node.state):\n",
    "            return current_node.state, current_node.step, cost\n",
    "\n",
    "        # Transforme l'état actuel en tuple pour le suivi des explorations\n",
    "        current_tuple = tuple(map(tuple, current_node.state))\n",
    "\n",
    "        # Si déjà exploré, passe à l'état suivant\n",
    "        if current_tuple in explored:\n",
    "            continue\n",
    "\n",
    "        # Marque l'état comme exploré\n",
    "        explored.add(current_tuple)\n",
    "\n",
    "        # Explore les actions possibles\n",
    "        for action in available_actions(current_node.state):\n",
    "            new_state = do_action(current_node.state, action)\n",
    "            frontier.append(Node(new_state, current_node.step + 1))\n",
    "\n",
    "    # Si aucune solution n'est trouvée\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state, quality, cost = n_puzzle_with_explored(state.copy())\n",
    "\n",
    "# ic(final_state)\n",
    "# ic(quality)\n",
    "# ic(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(state: np.ndarray) -> int:\n",
    "    \"\"\"Calcule la distance de Manhattan entre un état et la solution.\"\"\"\n",
    "    total_distance = 0\n",
    "    for x in range(PUZZLE_DIM):\n",
    "        for y in range(PUZZLE_DIM):\n",
    "            value = state[x, y]\n",
    "            if value == 0:\n",
    "                continue  # Ne calcule pas pour la case vide\n",
    "            target_x, target_y = divmod(value - 1, PUZZLE_DIM)\n",
    "            total_distance += abs(target_x - x) + abs(target_y - y)\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(order=True)\n",
    "class Node:\n",
    "    priority: int\n",
    "    state: list[list[int]] = field(compare=False)\n",
    "    step: int = field(compare=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop, heappush\n",
    "\n",
    "def n_puzzle_greedy_best_fit(state):\n",
    "    \"\"\"Résolution du N-Puzzle avec Greedy Best Fit.\"\"\"\n",
    "    frontier: list[Node] = []  # Utilise un tas (heap) pour prioriser les états\n",
    "    heappush(frontier, Node(manhattan_distance(state), state, 0))  # (distance, step, state)\n",
    "    explored = set()\n",
    "    cost = 0\n",
    "\n",
    "    while frontier:\n",
    "        cost += 1\n",
    "        current_node = heappop(frontier)\n",
    "\n",
    "        # Vérifie si la solution est atteinte\n",
    "        if np.array_equal(SOLUTION, current_node.state):\n",
    "            return current_node.state, current_node.step, cost\n",
    "\n",
    "        current_tuple = tuple(map(tuple, current_node.state))\n",
    "        if current_tuple in explored:\n",
    "            continue\n",
    "\n",
    "        explored.add(current_tuple)\n",
    "\n",
    "        # Ajoute les nouveaux états basés sur les actions possibles\n",
    "        for action in available_actions(current_node.state):\n",
    "            new_state = do_action(current_node.state, action)\n",
    "            heappush(frontier, Node(manhattan_distance(new_state), new_state, current_node.step + 1))\n",
    "\n",
    "    return None, None, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| final_state: array([[1, 2],\n",
      "                        [3, 0]])\n",
      "ic| quality: 0\n",
      "ic| cost: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state, quality, cost = n_puzzle_greedy_best_fit(state.copy())\n",
    "\n",
    "ic(final_state)\n",
    "ic(quality)\n",
    "ic(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci2024-lab3-93zH8EBI-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
